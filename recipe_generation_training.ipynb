{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73350761-bef2-4e96-b3ac-a158eabd2b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d8352af-343e-4c2e-8c91-95f8bac1c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 15000\n",
    "MAX_LEN = 256\n",
    "EMBEDDING_DIM = 256\n",
    "KEY_DIM = 256\n",
    "N_HEADS = 4\n",
    "FEED_FORWARD_DIM = 256\n",
    "SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93cf6b0f-9667-4146-8911-763a8a2925d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the full dataset\n",
    "# with open(\"full_format_recipes.json\") as json_data:\n",
    "#     recipes = json.load(json_data)\n",
    "    \n",
    "# # Filter the dataset\n",
    "# filtered_data = [\n",
    "#     \"Recipe for \" + x[\"title\"] + \" | \" + \" \".join(x[\"directions\"])\n",
    "#     for x in recipes\n",
    "#     if \"title\" in x\n",
    "#     and x[\"title\"] is not None\n",
    "#     and \"directions\" in x\n",
    "#     and x[\"directions\"] is not None\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77337837-9849-4553-ad12-635a3e20d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"recipes.txt\", 'r', encoding='utf-8') as f:\n",
    "    recipes = [line for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b2064fb-5dcc-4657-b470-0928d10e2ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pad the punctuation, to treat them as separate 'words'\n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(f\"([{string.punctuation}, '\\n'])\", r\" \\1 \", s)\n",
    "    s = re.sub(\" +\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "text_data = [pad_punctuation(x) for x in recipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b87d7c65-9a46-492a-a5c0-a043b0d252f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recipe for No - Bake Nut Cookies | In a heavy 2 - quart saucepan , mix brown sugar , nuts , evaporated milk and butter or margarine . Stir over medium heat until mixture bubbles all over top . Boil and stir 5 minutes more . Take off heat . Stir in vanilla and cereal ; mix well . Using 2 teaspoons , drop and shape into 30 clusters on wax paper . Let stand until firm , about 30 minutes . \\n '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9834f916-b21a-4104-acc9-f28d3bd7a8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 20:21:43.257510: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:43.291046: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:43.291235: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:43.292411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:43.292544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:43.292649: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:44.327795: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:44.327902: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:44.327980: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 20:21:44.328038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Convert to a Tensorflow Dataset\n",
    "text_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(text_data)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "884c0bcb-0807-45a1-8f7e-a32f2c6fa4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorisation layer\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower\",\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LEN + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d6dd34a-d905-497b-926a-405380ebcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the layer to the training set\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740294a1-1a6b-4c89-92f2-036d7d1b788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training set of recipes and the same text shifted by one word\n",
    "def prepare_inputs(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_ds = text_ds.map(prepare_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5285a1cb-fce1-46b1-b088-b596002fa9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "    )\n",
    "    return tf.tile(mask, mult)\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim, embed_dim, ff_dim, dropout_rate=0.2):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.attn = layers.MultiHeadAttention(\n",
    "            num_heads, key_dim, output_shape=embed_dim\n",
    "        )\n",
    "        self.dropout_1 = layers.Dropout(self.dropout_rate)\n",
    "        self.ln_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn_1 = layers.Dense(self.ff_dim, activation=\"relu\")\n",
    "        self.ffn_2 = layers.Dense(self.embed_dim)\n",
    "        self.dropout_2 = layers.Dropout(self.dropout_rate)\n",
    "        self.ln_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = causal_attention_mask(\n",
    "            batch_size, seq_len, seq_len, tf.bool\n",
    "        )\n",
    "        attention_output, attention_scores = self.attn(\n",
    "            inputs,\n",
    "            inputs,\n",
    "            attention_mask=causal_mask,\n",
    "            return_attention_scores=True,\n",
    "        )\n",
    "        attention_output = self.dropout_1(attention_output)\n",
    "        out1 = self.ln_1(inputs + attention_output)\n",
    "        ffn_1 = self.ffn_1(out1)\n",
    "        ffn_2 = self.ffn_2(ffn_1)\n",
    "        ffn_output = self.dropout_2(ffn_2)\n",
    "        return (self.ln_2(out1 + ffn_output), attention_scores)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"key_dim\": self.key_dim,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"ff_dim\": self.ff_dim,\n",
    "                \"dropout_rate\": self.dropout_rate,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, max_len, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_emb = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.pos_emb = layers.Embedding(input_dim=max_len, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"max_len\": self.max_len,\n",
    "                \"vocab_size\": self.vocab_size,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c57596e-e17d-4959-b6e8-7581b0bace3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=tf.int32)\n",
    "x = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
    "x, attention_scores = TransformerBlock(\n",
    "    N_HEADS, KEY_DIM, EMBEDDING_DIM, FEED_FORWARD_DIM\n",
    ")(x)\n",
    "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs=inputs, outputs=[outputs, attention_scores])\n",
    "model.compile(\"adam\", loss=[losses.SparseCategoricalCrossentropy(), None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a1c3b0f-3382-444d-bb04-bae143ae5d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, None, 256)         3905536   \n",
      " ng (TokenAndPositionEmbedd                                      \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " transformer_block (Transfo  ((None, None, 256),       1184512   \n",
      " rmerBlock)                   (None, 4, None, None))             \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 15000)       3855000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8945048 (34.12 MB)\n",
      "Trainable params: 8945048 (34.12 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ddcff5f-829d-4449-99d2-9a3cb68f7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(callbacks.Callback):\n",
    "    def __init__(self, index_to_word, top_k=10):\n",
    "        self.index_to_word = index_to_word\n",
    "        self.word_to_index = {\n",
    "            word: index for index, word in enumerate(index_to_word)\n",
    "        }\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "        return np.random.choice(len(probs), p=probs), probs\n",
    "\n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        start_tokens = [\n",
    "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
    "        ]\n",
    "        sample_token = None\n",
    "        info = []\n",
    "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
    "            x = np.array([start_tokens])\n",
    "            y, att = self.model.predict(x, verbose=0)\n",
    "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
    "            info.append(\n",
    "                {\n",
    "                    \"prompt\": start_prompt,\n",
    "                    \"word_probs\": probs,\n",
    "                    \"atts\": att[0, :, -1, :],\n",
    "                }\n",
    "            )\n",
    "            start_tokens.append(sample_token)\n",
    "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
    "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
    "        return info\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.generate(\"recipe for\", max_tokens=MAX_LEN, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "349865fe-ffbe-450e-97be-043ae1740e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model save checkpoint\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "# Tokenize starting prompt\n",
    "text_generator = TextGenerator(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "461c2b3e-b5ae-4def-8bd9-e7bab8c63d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 20:22:25.768059: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-07 20:22:28.919086: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fdd49ad6610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-07 20:22:28.919123: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2023-12-07 20:22:28.922184: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-07 20:22:29.205742: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701998549.247509 3231399 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34862/34862 [==============================] - ETA: 0s - loss: 1.0357 - dense_2_loss: 1.0357\n",
      "generated text:\n",
      "recipe for beef stroganoff | mince the beef in a pot with water , bouillon and bring to a boil . add the barley and cook until tender , about 5 minutes . while the meat is cooking , put the meat back on the heat and warm water to a boil . when the beef is done , remove it from the microwave . add the meat and add the gravy . let sit for about 20 minutes to cool . mix the meat with the flour , salt and pepper to taste . in a large skillet , melt the butter over low heat . when it has reduced , add the beef stock and garlic and cook for about 5 minutes . add the beef broth , sherry , and peas and simmer until the gravy thickens , about 5 minutes . serve over hot rice . \n",
      "\n",
      "34862/34862 [==============================] - 2641s 76ms/step - loss: 1.0357 - dense_2_loss: 1.0357\n",
      "Epoch 2/5\n",
      "34862/34862 [==============================] - ETA: 0s - loss: 0.9909 - dense_2_loss: 0.9909\n",
      "generated text:\n",
      "recipe for smoked salmon with yogurt and lime | preheat the oven to 425 degrees f . in a small bowl , whisk the yogurt , lime juice , and salt . season the salmon with salt and pepper and set aside . combine the yogurt , cilantro , lime juice , lime zest and lime zest and juice into a medium bowl . cover the bowl with plastic wrap and refrigerate until chilled , at least 4 hours . in a large bowl , combine the lime zest and the lime juice and mix well . whisk in the yogurt . season with salt and pepper , if desired . add more lime juice if desired . stir in salt and pepper to taste . serve hot , garnished with cilantro and lime zest . \n",
      "\n",
      "34862/34862 [==============================] - 2621s 75ms/step - loss: 0.9909 - dense_2_loss: 0.9909\n",
      "Epoch 3/5\n",
      "34862/34862 [==============================] - ETA: 0s - loss: 0.9821 - dense_2_loss: 0.9821\n",
      "generated text:\n",
      "recipe for salmon with dill | for the salmon : preheat the broiler . in a small bowl , combine the salmon , onion , dill and dill . in a small bowl , combine the dill , lemon juice and stir until the dill is dissolved . season with salt and pepper . rub the salmon all over the salmon fillets . cover and refrigerate the salmon fillets until just opaque in the center , about 4 to 5 minutes , or until the salmon is opaque and flaky . just before serving , toss with the salmon fillets . sprinkle with dill and dill . \n",
      "\n",
      "34862/34862 [==============================] - 2620s 75ms/step - loss: 0.9821 - dense_2_loss: 0.9821\n",
      "Epoch 4/5\n",
      "34862/34862 [==============================] - ETA: 0s - loss: 0.9777 - dense_2_loss: 0.9777\n",
      "generated text:\n",
      "recipe for rich and creamy chicken stock | combine all ingredients in a small saucepan . bring to a boil and cook 5 minutes or until reduced to a thick syrup . remove from heat and add chicken . season with salt and pepper . \n",
      "\n",
      "34862/34862 [==============================] - 2619s 75ms/step - loss: 0.9777 - dense_2_loss: 0.9777\n",
      "Epoch 5/5\n",
      "34862/34862 [==============================] - ETA: 0s - loss: 0.9748 - dense_2_loss: 0.9748\n",
      "generated text:\n",
      "recipe for creamy garlic chicken breasts | preheat oven to 350 degrees f . mix together the garlic powder , salt and pepper in a large bowl . place chicken breast in a shallow bowl . mix cream cheese , 1 tablespoon of the oil , the garlic and the thyme . place the chicken breasts on a baking sheet and bake for about 15 minutes , until the chicken is cooked through . remove from the oven and let rest for 2 to 3 minutes . serve with the salsa . \n",
      "\n",
      "34862/34862 [==============================] - 2619s 75ms/step - loss: 0.9748 - dense_2_loss: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fde4c3cbcd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback, tensorboard_callback, text_generator],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/new_recipe_generator/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/new_recipe_generator/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "model.save(\"./models/new_recipe_generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e02d2-84dc-40c8-8446-40c09adf1e20",
   "metadata": {},
   "source": [
    "# 3. Generate text using the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63a3e315-2993-4122-ad36-395a7e0b732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for vanilla whipped cream parfaits with berries | line large baking sheets with parchment paper or silicone baking mats . in 1 to 1 1 / 2 cups ( 750 ml ) of the 1 / 2 cups ( 125 ml ) of the sugar , and 1 / 2 cup ( 125 ml ) of the strawberry mixture . cover and refrigerate until the strawberries are ready to assemble dessert dishes . spoon 1 / 2 cup ( 175 ml ) parfait glasses and top with 2 tbsp ( 15 ml ) of the remaining 1 / 2 cup ( 125 ml ) whipped topping ( 1 / 2 cup ( 125 ml ) of the whipped topping ) crushed wafers ( 1 / 4 cup ( 125 ml ) of the strawberries ) and the remaining 1 cup ( 225 ml ) whipped topping . repeat with remaining whipped topping . top with remaining whipped topping and remaining whipped topping ; garnish with toasted pecans if desired . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for vanilla whipped cream parfaits with berries |\", max_tokens=256, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "325ff341-365d-4731-ae26-efadcc27a924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for chocolate chip cookies | preheat oven to 350 & line 2 rimmed baking sheets with parchment paper . cream butter and sugar until light and fluffy . add eggs , 1 at a time , beating well after each addition . add flour and baking soda and salt , to the creamed mixture and mix well . add the flour mixture to the creamed mixture alternately with the rest of the flour mixture . beat the egg whites until they form soft peaks . fold in macadamia nuts and chocolate chips . drop the dough by rounded teaspoons onto the prepared baking sheets . bake for 12 minutes or until golden brown . let cool on the baking sheets for 30 minutes . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chocolate chip cookies |\", max_tokens=256, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0142f8d-fd86-4354-b282-e86d174f980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for chicken noodle soup | combine all ingredients , except chicken . bring to boil , then lower heat . when chicken is cooked , remove chicken from liquid , drain & return to pot . add basil and lemon juice . stir well . return chicken to pot , and baste with sauce . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chicken noodle soup |\", max_tokens=256, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82c0b067-f67d-4d14-8e7f-cae6c23b7bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for sugar cookies | preheat oven to 350 degrees f . mix flour and baking soda in large bowl . using electric mixer , cream together the butter and sugars . add eggs , one at a time , beating well after each addition . stir in vanilla . add flour mixture to creamed mixture and stir to combine . add flour , soda , baking powder and salt . combine well . set aside . beat egg whites in another large bowl until foamy . gradually add the flour mixture , beating at low speed until just combined . stir in walnuts . drop by spoonfuls on ungreased cookie sheet . bake on cookie sheet for about 5 minutes . cool on wire rack for 10 minutes . transfer to wire rack and cool completely . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for sugar cookies |\", max_tokens=256, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18eaba31-9be0-4f4f-9bd5-7574d372c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for grilled cheese | butter a shallow baking dish . in a small bowl , combine the butter , lemon zest and juice from the lemon juice . season with salt and pepper . add the butter ; toss to combine . cover and refrigerate until ready to serve . for topping , heat the oven to 400 . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for grilled cheese |\", max_tokens=256, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "706e449e-1027-45f0-a609-7848fc523440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for chicken breast | preheat oven to 375 degrees f . coat chicken breasts with flour , salt and pepper , dip in buttermilk , then coat with flour . in a large skillet , heat oil over medium heat until hot ( about 2 minutes ) . once oil is hot , add chicken breasts , skin side down , and cook until golden brown on both sides , about 3 to 5 minutes . transfer chicken to a baking sheet and repeat with remaining breasts . bake for about 5 minutes , until chicken is cooked through and crispy . ( can be made 1 day ahead . cool , then cover and refrigerate . bring to room temperature before using . to make the chicken , melt butter in a large skillet over medium heat . add onion and garlic and cook until softened , about 7 minutes . add carrot , celery , green pepper , thyme , and salt and pepper to taste . add chicken , toss again to coat . transfer chicken breasts , skin side up and place on baking sheet . bake for about 1 hour . meanwhile , in a small bowl , combine cornstarch and water . working with chicken breasts , dip breasts among breasts . bake chicken breasts for about 25 minutes , then cover with foil and bake for 20 minutes , or until breasts are cooked through . while chicken is cooking , make cherry tomato sauce . serve immediately\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chicken breast |\", max_tokens=256, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3adc7-38c5-453c-8223-cfc99e2aade9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
